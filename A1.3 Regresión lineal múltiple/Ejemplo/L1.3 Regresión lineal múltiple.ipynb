{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5d8255bc",
      "metadata": {
        "id": "5d8255bc"
      },
      "source": [
        "# L1.3 Regresión lineal múltiple\n",
        "\n",
        "En esta lectura generaremos un modelo de regresión lineal múltiple, revisaremos si el modelo es útil (si alguna variable está asociada significativamente a la respuesta), analizaremos una variable de forma específica, y revisaremos la calidad del ajuste del modelo, tanto en datos de entrenamiento, como en datos de validación.\n",
        "\n",
        "Por favor no modifiques las celdas con las instrucciones, y solamente escribe código en las celdas donde así se te indica. **Si en algún momento seleccionas por error una celda de instrucciones y su apariencia cambia, simplemente presiona \"Ctrl + Enter\".**\n",
        "\n",
        "Dentro de las celdas de código, las líneas que inician con un \"\\#\" son comentarios y no se ejecutarán, simplemente sirven como instrucciones o descripciones útiles para ustedes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db0b474d",
      "metadata": {
        "id": "db0b474d"
      },
      "source": [
        "En este caso trabajaremos con los datos del Wine Quality Data Set, generados por Paulo Cortez y un grupo de investigación de la University of Minho, en Portugal, disponibles en [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/186/wine+quality). Los investigadores utilizaron estos datos para tratar de modelar las preferencias de consumo de vino, generando un índice de calidad. Nosotros trataremos de usar la información disponible, justamente para predecir dicho índice. Puedes encontrar la base de datos junto con el material del curso; el archivo lleva por nombre \"L1.3 Vino Tinto.csv\".\n",
        "\n",
        "En la primera celda cargaremos la base de datos en una variable de nombre `df` usando la función `read_csv`de la librería de pandas, revisaremos el tamaño de la base de datos con la función `shape` y revisaremos los nombres de las variables con el operador `columns`. No olvides asegurarte de que el archivo a leer esté en el mismo directorio donde se encuentra esta libreta.<br><br>\n",
        "\n",
        "<details>\n",
        "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
        "    import pandas as pd<br>\n",
        "    df = pd.read_csv(\"Vino Tinto.csv\")<br>\n",
        "    print(df.shape)<br>\n",
        "    print(df.columns)\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a2c988e",
      "metadata": {
        "id": "1a2c988e"
      },
      "outputs": [],
      "source": [
        "# Importa la librería pandas\n",
        "\n",
        "# Lee el archivo\n",
        "\n",
        "# Imprime en consola las dimensiones de los datos\n",
        "\n",
        "# Imprime en consola los nombres de las variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b76f3957",
      "metadata": {
        "id": "b76f3957"
      },
      "source": [
        "Como podrás notar, nuestra base de datos cuenta con 1599 observaciones distintas y 12 variables. Ya que una de esas variables, la calidad, será el valor a predecir, el modelo trabajará con 11 variables distintas: acidez fija, acidez volátil, ácido cítrico, azúcar residual, cloruros, dióxido de azufre libre, dióxido de azufre total, densidad, pH, sulfatos, y alcohol.\n",
        "\n",
        "Ya que nos interesa obtener al final del análisis tanto un error de entrenamiento, como uno de validación, separemos nuestra base de datos en dos, justamente en un subset de entrenamiento y uno de prueba. Primero realicemos el proceso por nuestra cuenta, de manera que entendamos lo que le sucede a los datos.\n",
        "\n",
        "El primer paso consistirá en usar el operador `sample` de pandas, para generar una muestra aleatoria de elementos de un objeto; especificaremos como parámetro que queremos obtener una fracción del 80% de los elementos originales. Almacenaremos el resultado de esta operación en una variable de nombre `train`.\n",
        "\n",
        "Posteriormente, generaremos una variable de nombre `test` donde almacenaremos los elementos que no fueron seleccionados para la etapa de entrenamiento. Para lograrlo, usaremos el operador `drop`, también de pandas, que se usa para eliminar ciertas filas (o columnas, dependiendo de la necesidad) de un *data frame*. Es decir, copiaremos la base de datos original, con excepción de las filas utilizadas para el subset de entrenamiento. Para determinar exactamente qué filas eliminar, usaremos el operador `index`, que entrega un identificador específico a cada observación.\n",
        "\n",
        "Para comprobar que el proceso fue exitoso, imprimiremos en consola las dimensiones de los nuevos subsets, así como las primeras 5 filas del set de entrenamiento.<br><br>\n",
        "\n",
        "<details>\n",
        "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
        "    train = df.sample(frac = 0.8)<br>\n",
        "    test = df.drop(train.index)<br>\n",
        "    print(\"Train:\", train.shape)<br>\n",
        "    print(\"Test:\",test.shape)<br>\n",
        "    print(train.head())\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c342672",
      "metadata": {
        "id": "1c342672"
      },
      "outputs": [],
      "source": [
        "# Genera datos de entrenamiento\n",
        "\n",
        "# Genera datos de validación\n",
        "\n",
        "# Imprime dimensiones de datos de entrenamiento\n",
        "\n",
        "# Imprime dimensiones de datos de prueba\n",
        "\n",
        "# Imprime primeras 5 filas de datos de entrenamiento\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daf2040b",
      "metadata": {
        "id": "daf2040b"
      },
      "source": [
        "Ahora sabemos que contamos con 1279 observaciones de entrenamiento y 320 de validación. Es común que los sets de validación sean mucho más pequeños que los de entrenamiento, pues entre mayor información utilicemos para entrenar, un mejor dempeseño tenderá a tener el modelo.\n",
        "\n",
        "Otra forma de lograr el mismo objetivo, es usando la función `train_test_split` de la librería sklearn.model_selection. En la siguiente celda repetiremos el proceso previo usando esta función, definiendo los nombres de los datasets de salida en la misma línea, y dando como argumentos el nombre del *data frame* original y el tamaño (proporción entre 0 y 1) del set de entrenamiento que deseamos obtener.\n",
        "\n",
        "Igualmente, validaremos que el proceso haya sido exitoso imprimiendo en consola las dimensiones de los nuevos subsets, y revisando las primeras 5 filas del subset de entrenamiento.<br><br>\n",
        "\n",
        "<details>\n",
        "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
        "    from sklearn.model_selection import train_test_split<br>\n",
        "    train, test = train_test_split(df, train_size = 0.8)<br>\n",
        "    print(\"Train:\", train.shape)<br>\n",
        "    print(\"Test:\",test.shape)<br>\n",
        "    print(train.head())\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd357682",
      "metadata": {
        "id": "bd357682"
      },
      "outputs": [],
      "source": [
        "# Importa la función train_test_split\n",
        "\n",
        "# Genera los datos de entrenamiento y validación\n",
        "\n",
        "# Imprime en consola las dimensiones de los datos de entrenamiento\n",
        "\n",
        "# Imprime en consola las dimensiones de los datos de prueba\n",
        "\n",
        "# Imprime en consola las primeras 5 filas de los datos de entrenamiento\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4961f2f",
      "metadata": {
        "id": "a4961f2f"
      },
      "source": [
        "Como podrás observar, obtuvimos los mismos resultados en términos del tamaño de los objetos. Pero, las observaciones  no son las mismas entre ambas metodologías. Esto no se debe a que el proceso sea distinto, sino que en ambos casos partimos de una selección aleatoria de sujetos. De hecho, si vuelven a correr las celdas anteriores varias veces, cada ocasión observarán un resultado distinto.\n",
        "\n",
        "Es momento de realizar la regresión lineal múltiple. En esta ocasión nos apoyaremos de la misma función que utilizamos en la lectura interactiva del Módulo 3, `OLS` de la librería statsmodels.api. Primero definiremos $X$ y $Y$ a partir de los datos de entrenamiento; para generar el primer elemento simplemente eliminaremos la columna `calidad` del dataset `train` usando el operador `drop`; para el segundo elemento simplemente tomaremos dicha columna. Después definieremos el modelo `model` con la función `OLS`, utilizando como parámetros `Y` y `sm.add_constant(X)` para asegurarnos que el modelo incluya $\\beta_0$. Finalmente, estimaremos el valor de cada coeficiente con el método `fit`, almacenando los resultados en `results`. Para revisar los resultados obtenido, imprimiremos en pantalla un resumen utilizando el método `summary()`.<br><br>\n",
        "\n",
        "<details>\n",
        "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
        "    import statsmodels.api as sm<br>\n",
        "    X = train.drop('calidad', axis = 1)<br>\n",
        "    Y = train.calidad<br>\n",
        "    model = sm.OLS(Y,sm.add_constant(X))<br>\n",
        "    results = model.fit()<br>\n",
        "    print(results.summary())\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d01f8296",
      "metadata": {
        "scrolled": true,
        "id": "d01f8296"
      },
      "outputs": [],
      "source": [
        "# Importar librería\n",
        "\n",
        "# Generar elemento X\n",
        "\n",
        "# Generar elemento Y\n",
        "\n",
        "# Definir el tipo de modelo\n",
        "\n",
        "# Ajustar el modelo para obtener resultados\n",
        "\n",
        "# Imprimir un resumen de los resultados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44bf6e78",
      "metadata": {
        "id": "44bf6e78"
      },
      "source": [
        "En el resumen de resultados previo podemos revisar múltiples detalles. Por ejemplo: el valor de cada uno de los coeficientes del modelo, el *p-value* asociado a cada uno de dichos coeficientes bajo una prueba de significancia de coeficientes individuales, el intervalo de confianza para cada coeficiente, el estadístico *F* y su *p-value* asociado, el valor de la $R^2$, etc. Sin embargo, por única ocasión, tratemos de comprobar si lo aprendido previamente nos ayuda a calcular por nuestra cuenta algunos de estos valores.\n",
        "\n",
        "Antes de hacerlo, revisa con atención las características del modelo. El *p-value* asociado al estadístico *F* nos indica que sí hay al menos una variable asociada de forma significativa con la salida. Adicionalmente, los *p-values* de los coeficientes individuales nos muestran qué variables específicamente son de interés (acidez volátil, cloruros, y alcohol, por ejemplo).\n",
        "\n",
        "Primero calcularemos el estadístico *F*, tal y como se describió en clase. Empezaremos calculando el EMS y el RMS a partir del ESS y del RSS; recuerden que el ESS se define como la sumatoria de la diferencia cuadrada entre el valor estimado de $Y$ y el valor promedio de $Y$, mientras que el RSS se define como la sumatoria de la diferencia cuadrada entre el valor actual de $Y$ y el valor estimado de $Y$.\n",
        "\n",
        "Realizarems este proceso en múltiples pasos:\n",
        "1. Estimar el valor de $Y$ a partir de los coeficientes estimados del modelo, usando el método `predict` sobre los datos `X`, tras agregarles una columna de unos con la función `add_constant`. En sí, esta función simplemente realiza el producto punto entre los datos y los coeficientes del modelo.\n",
        "2. Calcular el valor promedio de $Y$, usando la función `mean` de numpy.\n",
        "3. Calcular ESS.\n",
        "4. Calcular $m$ como la cantidad de variables de los datos de entrenamiento, usando la función `shape` y tomando solo el segundo elemento `[1]`.\n",
        "5. Calcular EMS (ESS/m).\n",
        "6. Calcular RSS.\n",
        "7. Calcular $n$ como la cantidad de observaciones de los datos de entrenamiento, usando la función `shape` y tomando solo el primero elemento `[0]`.\n",
        "8. Calcular RMS (RSS/(n-m-1)).\n",
        "9. Calcular F (EMS/RMS).\n",
        "10. Calcular el *p-value* asociado a dicho estadístico *F*. Para lograrlo, usaremos la función `f.sf` de la librería scipy.stats, incluyendo como parámetros el valor de *F*, los grados de libertas del EMS (m), y los grados de libertas del RMS (n-m-1).\n",
        "\n",
        "Al finalizar, imprimiremos en consola el valor del estadístico *F* y de su *p-value* asociado, para comprobar que son iguales a los resultados mostrados en el `summary` del modelo. Recuerda que deberás importar ambas librerías consideradas en los pasos previos.<br><br>\n",
        "\n",
        "<details>\n",
        "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
        "    import scipy.stats as st<br>\n",
        "    import numpy as np<br>\n",
        "    yhat = results.predict(sm.add_constant(X))<br>\n",
        "    ybar = np.mean(Y)<br>\n",
        "    ESS = sum((yhat - ybar)**2)<br>\n",
        "    m = X.shape[1]<br>\n",
        "    EMS = ESS / m<br>\n",
        "    RSS = sum((Y - yhat)**2)<br>\n",
        "    n = X.shape[0]<br>\n",
        "    RMS = RSS / (n - m - 1)<br>\n",
        "    F = EMS / RMS<br>\n",
        "    pval = st.f.sf(F, m, n - m - 1)<br>\n",
        "    print(\"F =\", F)<br>\n",
        "    print(\"p-value =\", pval)\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0280b7d6",
      "metadata": {
        "scrolled": true,
        "id": "0280b7d6"
      },
      "outputs": [],
      "source": [
        "# Importar librerías\n",
        "\n",
        "\n",
        "# Calcular Y estimada\n",
        "\n",
        "# Calcular el promedio de Y\n",
        "\n",
        "# Calcular el ESS\n",
        "\n",
        "# Calcular m\n",
        "\n",
        "# Calcular EMS\n",
        "\n",
        "# Calcular RSS\n",
        "\n",
        "# Calcular n\n",
        "\n",
        "# Calcular RMS\n",
        "\n",
        "# Calcular el estadístico F\n",
        "\n",
        "# Calcular el p-value\n",
        "\n",
        "# Imprimir el valor de F\n",
        "\n",
        "# Imprimir el p-value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2c571b5",
      "metadata": {
        "id": "a2c571b5"
      },
      "source": [
        "Si todo salió bien, los resultados deben ser los mismos que los obtenidos mediante la función `OLS`. Ahora revisemos el *p-value* de un coeficiente individual, trabajemos con el nivel de alcohol. Si recuerdan, en clase indicamos que para hacer esto, necesitamos primero generar un nuevo modelo, muy similar al que ya generamos, pero para el que los datos no incluyan a la variables de interés, el nivel de alcohol en este caso.\n",
        "\n",
        "Empecemos con eso, definamos `XNew` como `X` sin la columna de alcohol usando la función `drop`. Generemos un nuevo modelo usando la función `OLS` y estos nuevos datos, pero usando la misma variable de salida `Y`. Ajustemos el modelo, para así obtener los coeficientes estimados, usando el método `fit()`. Listo, tenemos un nuevo modelo que no incluye la variable de interés.<br><br>\n",
        "\n",
        "<details>\n",
        "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
        "    XNew = X.drop('alcohol', axis = 1)<br>\n",
        "    modelNew = sm.OLS(Y,sm.add_constant(XNew))<br>\n",
        "    resultsNew = modelNew.fit()\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e90a80a4",
      "metadata": {
        "id": "e90a80a4"
      },
      "outputs": [],
      "source": [
        "# Genera el nuevo elemento X, sin la variable alcohol\n",
        "\n",
        "# Define el nuevo modelo\n",
        "\n",
        "# Ajusta el nuevo modelo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e75c0c3a",
      "metadata": {
        "id": "e75c0c3a"
      },
      "source": [
        "Ahora calculemos el *p-value* asociado, siguiendo la ecuación mostrada en clase. Realizaremos una serie de pasos muy similares a los usados para calcular el estadístico *F* global:\n",
        "1. Estimar el nuevo valor de $Y$ usando el método `predict` en los nuevos datos.\n",
        "2. Calcular el nuevo valor del RSS.\n",
        "3. Calcular el nuevo valor del EMS ((RSSNew - RSS)/1).\n",
        "4. Obtener el nuevo valor de F (EMSNew/RMS).\n",
        "5. Calcular el *p-value* asociado a dicho estadístico.\n",
        "6. Ya que lo que el `summary` muestra es el valor del estadístico *t*, calculamos dicho valor como la raíz cuadrada de *F* con la función `sqrt` de numpy.\n",
        "\n",
        "Ahora solo resta imprimir en consola cada uno de estos valores (nuevo valor de *F*, *t*, y nuevo *p-value*) y compararlos con los que muestra la tabla del `summary` unas cuantas celdas arriba de esta. Si el *p-value* del alcohol solo se lee como 0.000, usa el atributo `pvalues` para la columna `alcohol` en la variable de resultados, e imprime dicho valor en consola.<br><br>\n",
        "\n",
        "<details>\n",
        "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
        "    yhatNew = resultsNew.predict(sm.add_constant(XNew))<br>\n",
        "    RSSNew = sum((Y-yhatNew)**2)<br>\n",
        "    EMSNew = (RSSNew - RSS) / 1<br>\n",
        "    FNew = EMSNew / RMS<br>\n",
        "    pvalNew = st.f.sf(FNew, 1, n-m-1)<br>\n",
        "    t = np.sqrt(FNew)<br>\n",
        "    print(\"New F =\", FNew)<br>\n",
        "    print(\"t-value =\", t)<br>\n",
        "    print(\"p-value =\", pvalNew)<br>\n",
        "    print(\"OLS's p-value =\", results.pvalues.alcohol)\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38845b56",
      "metadata": {
        "id": "38845b56"
      },
      "outputs": [],
      "source": [
        "# Realiza las nuevas estimaciones de Y\n",
        "\n",
        "# Calcula el nuevo RSS\n",
        "\n",
        "# Calcula el nuevo EMS\n",
        "\n",
        "# Calcula el nuevo estadístico F\n",
        "\n",
        "# Obtén el nuevo p-value\n",
        "\n",
        "# Calcula el estadístico t como la raíz cuadrada de F\n",
        "\n",
        "# Imprime el nuevo valor de F\n",
        "\n",
        "# Imprime el valor de t\n",
        "\n",
        "# Imprime el p-value\n",
        "\n",
        "# Imprime el p-value entregado por la función OLS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65c3d025",
      "metadata": {
        "id": "65c3d025"
      },
      "source": [
        "Con esto, hemos comprobado que somos capaces de generar y analizar los resultados de una regresión lineal múltiple, incluso si en la práctica dejamos de calcular cada una de estas métricas de forma manual en el futuro. Pero, aún queda algo pendiente, recuerda que en un inicio separamos nuestros datos en `train` y `test`. Revisemos el ajuste del modelo en los datos de validación, calculando tanto el RSE como la $R^2$, siguiendo las ecuaciones mostradas en clase.\n",
        "\n",
        "De nuevo, seguiremos una serie de pasos:\n",
        "1. Generar `XTest` de forma similar a como se generó `X`, pero usando solo los datos de `test`.\n",
        "2. Estimar el valor de $Y$ para los datos de validación.\n",
        "3. Generar `YTest` de forma similar a como se generó `Y`.\n",
        "4. Calcular RSSTest.\n",
        "5. Calcular TSSTest, estimando el promedio de `YTest` con la función `mean` de numpy.\n",
        "6. Obtener el valor de `nTest`, la cantidad de observaciones de los datos de validación (debe tener un valor distinto a `n`, pues hay más sujetos en el set de entrenamiento que en el de validación).\n",
        "7. Obtener el valor de `mTest`, la cantidad de variables en los datos de validación (debe tener el mismo valor que `m`, pues usamos las mismas variables para entrenar y validar).\n",
        "8. Calcular RSETest (*residual standard error* en validación).\n",
        "9. Calcular R2Test (R cuadrada en validación).\n",
        "\n",
        "Al finalizar, imprime ambas métricas en consola.<br><br>\n",
        "\n",
        "<details>\n",
        "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
        "    XTest = test.drop('calidad', axis = 1)<br>\n",
        "    yhatTest = results.predict(sm.add_constant(XTest))<br>\n",
        "    YTest = test.calidad<br>\n",
        "    RSSTest = sum((YTest-yhatTest)**2)<br>\n",
        "    TSSTest = sum((YTest-np.mean(YTest))**2)<br>\n",
        "    nTest = XTest.shape[0]<br>\n",
        "    mTest = XTest.shape[1]<br>\n",
        "    RSETest = np.sqrt(RSSTest/(n-m-1))<br>\n",
        "    R2Test = 1 - RSSTest / TSSTest<br>\n",
        "    print(\"RSE =\", RSETest)<br>\n",
        "    print(\"R^2 =\", R2Test)<br>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b96ccba",
      "metadata": {
        "id": "8b96ccba"
      },
      "outputs": [],
      "source": [
        "# Genera el elemento XTest\n",
        "\n",
        "# Estima los valores de Y para los datos de validación\n",
        "\n",
        "# Genera el elemento YTest\n",
        "\n",
        "# Calcula el RSS de validación\n",
        "\n",
        "# Calcula el TSS de validación\n",
        "\n",
        "# Define el valor de n para los datos de prueba\n",
        "\n",
        "# Define el valor de m para los datos de prueba\n",
        "\n",
        "# Calcula el RSE de validación\n",
        "\n",
        "# Calcula el R^2 de validación\n",
        "\n",
        "# Imprime el RSE\n",
        "\n",
        "# Imprime el R^2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6becc9a",
      "metadata": {
        "id": "c6becc9a"
      },
      "source": [
        "En esta ocasión, los valores obtenidos no serán los mismos que los que se observan en `summary`, pues se está trabajando con otros datos. Sin embargo, es importante revisar que la diferencia no sea muy grande, pues eso indicaría problemas en nuestro modelo, típicamente relacionados a *overfitting*. Si estás interesado en revisar el RSE de entrenamiento, dicha métrica no se muestra en la tabla. Sin embargo, dicho valor puede calcularse de forma sencilla como la raíz cuadrada del atributo `scale` de los resultados.\n",
        "\n",
        "Listo, hemos terminado un análisis muy completo. Estás listo para realizar tus propios análisis e interpretar sus resultados."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}