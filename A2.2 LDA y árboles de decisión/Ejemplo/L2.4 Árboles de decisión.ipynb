{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b450135a",
   "metadata": {},
   "source": [
    "# L2.4 Árboles de decisión\n",
    "\n",
    "A lo largo de este curso estaremos trabajando con estas *Jupyter Notebooks*, tratando de poner en práctica los conceptos aprendidos en cada módulo. Pero, también las utilizaremos como herramienta de lectura para, antes de programar nuestro propio código, conocer cómo se usan algunas funciones, aprender sobre distintas librerías, etc.\n",
    "\n",
    "En esta lectura generaremos árboles de decisión para un problema de clasificación.\n",
    "\n",
    "Por favor no modifiques las celdas con las instrucciones, y solamente escribe código en las celdas donde así se te indica. **Si en algún momento seleccionas por error una celda de instrucciones y su apariencia cambia, simplemente presiona \"Ctrl + Enter\".**\n",
    "\n",
    "Dentro de las celdas de código, las líneas que inician con un \"\\#\" son comentarios y no se ejecutarán, simplemente sirven como instrucciones o descripciones útiles para ustedes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2c8fea",
   "metadata": {},
   "source": [
    "En esta ocasión trabajaremos con la base de datos de Kaggle titulada *Kyphosis Dataset*, una base de datos que contiene 81 observaciones y 4 variables:\n",
    " - `Kyphosis`. absent o present, si se observa cifosis o no después de la operación.\n",
    " - `Age`. Edad, en meses.\n",
    " - `Number`. Cantidad de vértebras involucradas.\n",
    " - `Start`. Número de la vértebra más alta involucrada en la operación\n",
    " \n",
    "Los datos fueron proporcionados originalmente por John M. Chambers y Trevor J. Hastle, y se descargaron directamente de [Kaggle](https://www.kaggle.com/datasets/abbasit/kyphosis-dataset).\n",
    " \n",
    "Iniciemos como siempre, importando los datos a nuestro ambiente de trabajo. En esta ocasión el archivo lleva por nombre \"L2.4 Kyphosis.csv\". Adicionalmente, separa las variables de entrada de la variable de salida, designándolos como `X` y `y`.<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    import pandas as pd<br>\n",
    "    db = pd.read_csv(\"L2.4 Kyphosis.csv\")<br>\n",
    "    X = db.drop(['Kyphosis'],axis=1)<br>\n",
    "    y = pd.get_dummies(db['Kyphosis'],drop_first=True)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f74686e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa pandas\n",
    "\n",
    "# Lee el archivo\n",
    "\n",
    "# Separa las entradas y la salida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921283d7",
   "metadata": {},
   "source": [
    "Ahora, separemos nuestros datos en un set de entrenamiento y uno de prueba, utilizando una proporción de 85/15, y asegurándonos de que cada subconjunto tenga una proporción similar de clases en la variable de salida. Recuerda que puedes definir dicha condción usando el parámetro stratify de la función `train_test_split`. Asegúrate de que las proporciones sean las adecuadas imprimiendo la cantidad de muestras de cada clase para los datos originales, y para cada subconjunto.<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    from sklearn.model_selection import train_test_split<br>\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y)<br>\n",
    "    print(db.Kyphosis.value_counts())<br>\n",
    "    print(y_train.value_counts())<br>\n",
    "    print(y_test.value_counts())\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9998293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la librería necesaria\n",
    "\n",
    "# Separar los datos\n",
    "\n",
    "# Imprimir las proporciones\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c713b",
   "metadata": {},
   "source": [
    "Muy bien, llegó momento de generar y entrenr nuestro modelo. En esta ocasión volveremos a usar una función de sklearn, específicamente de la librería sklearn.tree. La función tiene por nombre `DecisionTreeClassifier`, pero te recomiendo que la importes como `DTC`. Trata de crear y entrenar el modelo en la misma línea de código. Obviamente, solo debemos usar los datos de entrenamiento.<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    from sklearn.tree import DecisionTreeClassifier as DTC<br>\n",
    "    tree = DTC().fit(X_train, y_train)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "997798c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librería\n",
    "\n",
    "# Crear y entrenar modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f9123",
   "metadata": {},
   "source": [
    "Inspeccionemos visualmente nuestro árbol. Importa la función `plot_tree` de sklearn.tree, y llámala dando como parámetro el modelo recién entrenado. Te recomiendo definir filled=True y feature_names con los nombres de tus variables, para que la gráfica sea más interpretable. Adicionalmente, te recomiendo agregar un punto y coma a esa línea de código para evitar desplegar el texto que esa función genera. También te aconsejo aumentar el tamaño de la gráfica a (15,10) con el parámetro figsize dentro de la función `plt.figure` (aunque el valor más adecuado dependerá de tu monitor).<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    import matplotlib.pyplot as plt<br>\n",
    "    %matplotlib inline<br>\n",
    "    from sklearn.tree import plot_tree<br>\n",
    "    plt.figure(figsize=(15,10))<br>\n",
    "    plot_tree(tree, filled=True, feature_names=X_train.columns);\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7845d174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la librería para generar gráficas\n",
    "\n",
    "# Función mágica\n",
    "\n",
    "# Importa plot_tree\n",
    "\n",
    "# Define el tamaño de la figura\n",
    "\n",
    "# Genera la gráfica del árbol de decisión\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f5a3f",
   "metadata": {},
   "source": [
    "Revisemos ahora la calidad del modelo inicial en los datos de prueba, realizando una predicción en los mismos con nuestro modelo. Calcula tanto el accuracy como el f1-score, importando las funciones `accuracy_score` y `f1_score` de la librería sklearn.metrics. Imprime los resultados.<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    from sklearn.metrics import accuracy_score, f1_score<br>\n",
    "    yhat0 = tree.predict(X_test)<br>\n",
    "    acc0 = accuracy_score(y_test, yhat0)<br>\n",
    "    f10 = f1_score(y_test, yhat0)<br>\n",
    "    print(\"Accuracy inicial:\",acc0)<br>\n",
    "    print(\"F1-score inicial:\",f10)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c597204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa las métricas\n",
    "\n",
    "# Realiza la predicción\n",
    "\n",
    "# Calcula accuracy\n",
    "\n",
    "# Calcula f1\n",
    "\n",
    "# Imprime resultados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ff4d1",
   "metadata": {},
   "source": [
    "Tratemos ahora de podar nuestro árbol, definiendo el valor adecuado de $\\alpha$ usando una validación cruzada de 4 folds. Trataré de apoyarte paso a paso en este proceso; primero, importa numpy, así como las funciones `cross_val_score` y `StratifiedKFold` de sklearn.mode_selection. La primera función la usaremos para calcular un métrica de calida en un formato de validación cruzada. Sin embargo, dicha función no permite que la separación en *folds* se lleve a cabo de forma estratificada. Por lo mismo usaremos la segunda función para generar dicha separación.\n",
    "\n",
    "Utiliza la función `StratifiedKFold` con el parámetro n_splits=4 para crear un sistema de separación de datos adecuado. Después, crea un vector de posibles valores para $\\alpha$ con la función `linspace` de numpy, que genera secuencias numéricas con espaciado constante. A dicha función indícale un valor inicial (0.001), un valor final (0.2) y la cantidad de valores que quieres que se incluyan en la secuencia (entre 100 y 250). Inicializa un vector donde se almacenarán los resultados de cada *fold*.\n",
    "\n",
    "Genera un ciclo for que recorra todos los valores del vector de posibles $\\alpha$. En cada ciclo, genera un nuevo árbol, pero especificando el factor de corrección con el parámetro ccp_alpha. Después, calcula el f1-score y almacénalo en la variable previamente inicializada, promediando la salida de la función `cross_val_score`. Dicha función requiere que le indiques como parámetros el modelo que usará, los datos de entrenamiento (tanto `X` como `y`), el objeto de validación cruzada, y la métrica a utilizar. Asegúrate de usar el operador `append` para almacenar todos los resultados de las iteraciones.<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    import numpy as np<br>\n",
    "    from sklearn.model_selection import cross_val_score, StratifiedKFold<br>\n",
    "    skf = StratifiedKFold(n_splits=4)<br>\n",
    "    ccp = np.linspace(0.001, 0.2, 250)<br>\n",
    "    cv_scores = []<br>\n",
    "    for alpha in ccp:<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pruned_tree = DTC(ccp_alpha=alpha)<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cv_scores.append(np.mean(cross_val_score(pruned_tree, X_train, y_train, cv=skf, scoring='f1')))\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6821e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar numpy\n",
    "\n",
    "# Importar funciones de validación cruzada\n",
    "\n",
    "# Generar objeto de validación cruzada\n",
    "\n",
    "# Generar secuencia de valores\n",
    "\n",
    "# Inicializar variable de salida\n",
    "\n",
    "# Ciclo donde se calcula el f1-score mediante validación cruzada\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f77a0",
   "metadata": {},
   "source": [
    "Excelente, revisemos ahora qué valor de alpha es óptimo para este sistema. Te recomiendo encontrar dicho valor usando la función `argmax` de numpy en el vector de resultados, y ubicar dentro del vector de posibles $\\alpha$ el valor que corresponde a dicha posición. Imprime el resultado.<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    alpha = ccp[np.argmax(cv_scores)]<br>\n",
    "    print(\"Best alpha:\",alpha)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45aa0d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar el alpha óptimo\n",
    "\n",
    "# Imprimir resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f3fd70",
   "metadata": {},
   "source": [
    "Ahora visualicemos nuestro árbol podado y revisemos que tantas o tan pocas hojas le quedaron.<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    pruned_tree = DTC(ccp_alpha=alpha).fit(X_train, y_train)<br>\n",
    "    plot_tree(pruned_tree, filled=True, feature_names=X_train.columns);\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86aa3208",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generar y entrenar el árbol podado\n",
    "\n",
    "# Visualizar árbol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399a6922",
   "metadata": {},
   "source": [
    "Analicemos ahora su calidad, usando las mismas métricas con que revisamos al árbol original.<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    yhat_p = pruned_tree.predict(X_test)<br>\n",
    "    acc_p = accuracy_score(y_test, yhat_p)<br>\n",
    "    f1_p = f1_score(y_test, yhat_p)<br>\n",
    "    print(\"Accuracy final:\",acc_p)<br>\n",
    "    print(\"F1-score final:\",f1_p)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c080d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones del nuevo modelo\n",
    "\n",
    "# Accuracy\n",
    "\n",
    "# F-1 score\n",
    "\n",
    "# Imprimir resultados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4365fe",
   "metadata": {},
   "source": [
    "Excelente trabajo, con esto damos por finalizada la lectura de esta sesión."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
