{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e449d89",
   "metadata": {
    "id": "3e449d89"
   },
   "source": [
    "# L1.4 Selección de características\n",
    "\n",
    "En esta lectura realizaremos métodos de selección de características: selección hacia adelante, eliminación hacia atrás, y Lasso.\n",
    "\n",
    "Por favor no modifiques las celdas con las instrucciones, y solamente escribe código en las celdas donde así se te indica. **Si en algún momento seleccionas por error una celda de instrucciones y su apariencia cambia, simplemente presiona \"Ctrl + Enter\".**\n",
    "\n",
    "Dentro de las celdas de código, las líneas que inician con un \"\\#\" son comentarios y no se ejecutarán, simplemente sirven como instrucciones o descripciones útiles para ustedes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e815270",
   "metadata": {
    "id": "8e815270"
   },
   "source": [
    "Una vez más trabajaremos con los datos del Wine Quality Data Set, generados por Paulo Cortez y un grupo de investigación de la University of Minho, en Portugal, disponibles en [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/186/wine+quality). Como ya lo sabes, los investigadores utilizaron estos datos para tratar de modelar las preferencias de consumo de vino, generando un índice de calidad. Nosotros ya usamos la información disponible en el módulo anterior para predecir dicho índice. Ahora, trataremos de mejorar la precisión del modelo a través de metodologías de selección de características. Puedes encontrar la base de datos junto con el material del curso; el archivo lleva por nombre \"L1.4 Vino Tinto.csv\".\n",
    "\n",
    "En la primera celda cargaremos la base de datos en una variable de nombre `df` usando la función `read_csv`de la librería de pandas, revisaremos el tamaño de la base de datos con la función `shape` y revisaremos los nombres de las variables con el operador `columns`. No olvides asegurarte de que el archivo a leer esté en el mismo directorio donde se encuentra esta libreta.<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    import pandas as pd<br>\n",
    "    df = pd.read_csv(\"Vino Tinto.csv\")<br>\n",
    "    print(df.shape)<br>\n",
    "    print(df.columns)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2aa82ca",
   "metadata": {
    "id": "f2aa82ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 12)\n",
      "Index(['acidezFija', 'acidezVolatil', 'acidoCitrico', 'azucarResidual',\n",
      "       'cloruros', 'dioxidoAzufreLibre', 'dioxidoAzufreTotal', 'densidad',\n",
      "       'pH', 'sulfatos', 'alcohol', 'calidad'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Importa la librería pandas\n",
    "import pandas as pd\n",
    "# Lee el archivo\n",
    "df = pd.read_csv(\"L1.4 Vino Tinto.csv\")\n",
    "# Imprime en consola las dimensiones de los datos\n",
    "print(df.shape)\n",
    "# Imprime en consola los nombres de las variables\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b9dfe5",
   "metadata": {
    "id": "68b9dfe5"
   },
   "source": [
    "Realizaremos algunos pasos que ya se realizaron en la lectura del módulo anterior, desde la separación en subconjuntos de entenamiento y prueba, hasta la creación de un modelo de regresión múltiple que incluya todas las variables del sistema. Si tienes alguna duda sobre cómo realizar estos pasos, te invito a que revises con detalle la lectura interactiva anterior.<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    from sklearn.model_selection import train_test_split<br>\n",
    "    train, test = train_test_split(df, train_size = 0.8)<br>\n",
    "    import statsmodels.api as sm<br>\n",
    "    X = train.drop('calidad', axis = 1)<br>\n",
    "    Y = train.calidad<br>\n",
    "    model = sm.OLS(Y,sm.add_constant(X))<br>\n",
    "    results = model.fit()<br>\n",
    "    print(results.summary())\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e8e90a2",
   "metadata": {
    "id": "1e8e90a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                calidad   R-squared:                       0.378\n",
      "Model:                            OLS   Adj. R-squared:                  0.372\n",
      "Method:                 Least Squares   F-statistic:                     69.96\n",
      "Date:                Mon, 21 Aug 2023   Prob (F-statistic):          2.68e-122\n",
      "Time:                        08:10:03   Log-Likelihood:                -1246.9\n",
      "No. Observations:                1279   AIC:                             2518.\n",
      "Df Residuals:                    1267   BIC:                             2580.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                 29.4612     23.267      1.266      0.206     -16.185      75.108\n",
      "acidezFija             0.0289      0.029      1.014      0.311      -0.027       0.085\n",
      "acidezVolatil         -1.1584      0.135     -8.555      0.000      -1.424      -0.893\n",
      "acidoCitrico          -0.1916      0.165     -1.160      0.246      -0.516       0.132\n",
      "azucarResidual         0.0186      0.016      1.141      0.254      -0.013       0.050\n",
      "cloruros              -1.6488      0.471     -3.502      0.000      -2.573      -0.725\n",
      "dioxidoAzufreLibre     0.0029      0.002      1.234      0.217      -0.002       0.008\n",
      "dioxidoAzufreTotal    -0.0027      0.001     -3.380      0.001      -0.004      -0.001\n",
      "densidad             -25.8274     23.741     -1.088      0.277     -72.403      20.749\n",
      "pH                    -0.3158      0.210     -1.505      0.133      -0.727       0.096\n",
      "sulfatos               0.9190      0.126      7.278      0.000       0.671       1.167\n",
      "alcohol                0.2832      0.029      9.774      0.000       0.226       0.340\n",
      "==============================================================================\n",
      "Omnibus:                       29.462   Durbin-Watson:                   1.942\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               45.218\n",
      "Skew:                          -0.214   Prob(JB):                     1.52e-10\n",
      "Kurtosis:                       3.816   Cond. No.                     1.13e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.13e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Importa la función train_test_split de la librería skleanr.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Genera los datos de entrenamiento (80%) y validación (20%)\n",
    "train, test = train_test_split(df, train_size = 0.8)\n",
    "# Importar librería statsmodels.api\n",
    "import statsmodels.api as sm\n",
    "# Generar elemento X\n",
    "X = train.drop('calidad', axis = 1)\n",
    "# Generar elemento Y\n",
    "Y = train.calidad\n",
    "# Definir el tipo de modelo\n",
    "model = sm.OLS(Y,sm.add_constant(X))\n",
    "# Ajustar el modelo para obtener resultados\n",
    "results = model.fit()\n",
    "# Imprimir un resumen de los resultados\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eb814a",
   "metadata": {
    "id": "b8eb814a"
   },
   "source": [
    "Hasta este punto debimos haber obtenido resultados muy similares a los obtenidos en la lectura interactiva anterior (las diferencias son causadas por la separación aleatoria de datos en los subconjuntos de entrenamiento y prueba). El modelo tiene una R cuadrada ajustada baja (probablemente ligeramente menor a 0.4), y múltiples variables tienen un *p-value* mayor a 0.05.\n",
    "\n",
    "Es momento de iniciar con la selección de características. En este caso, trabajaremos con la selección hacia adelante rápida. Como probablemente recuerdes, el primer paso en esta metodología consiste en genear un *ranking* de las variables. En esta ocasión utilizaremos la correlación de Pearson para generar dicho ranking, métrica que puede calcularse usando la función `pearsonr` de la librería scipy.stats. Dicha función entrega tanto el valor de correlación, como su *p-value* asociado. Ya que de momento solo nos interesa la correlación, únicamente almacenaremos el primer valor (índice 0) entregado por la función. Adicionalmente, ya que solo nos interesa la magnitud de la correlación, y no su dirección, trabajaremos con el valor absoluto de la métrica, apoyándonos con la función `abs`.\n",
    "\n",
    "En la siguiente celda, primero importaremos la función necesaria, después generarmos una variable de nombre `n` donde se almacene la cantidad de variables por analizar, y después inicializaremos un vector de zeros, usando la función `zeros` de numpy, donde eventualmente se guardarán los datos de correlación.\n",
    "\n",
    "Para poder realizar la prueba de correlación entre cada columna de X e Y, utilizaremos un ciclo for (la indentación de la línea posterior al for es de suma importancia). Allí se realizará la prueba entre la primera columna de X e Y y se almacenará el valor en la primera posición del vector previamente inicializado. Después se realizará el mismo proceso entre la segunda columna de X e Y, después entre la tercera columna de X e Y, y así sucesivamente hasta analizar todas las variables. Finalmente, imprimiremos en consola los resultados.\n",
    "<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    from scipy.stats import pearsonr<br>\n",
    "    import numpy as np<br>\n",
    "    n = X.shape[1]<br>\n",
    "    cor = np.zeros(n)<br>\n",
    "    for i in range(n):<br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cor[i] = abs(pearsonr(X.iloc[:, i], Y)[0])<br>\n",
    "    print(cor)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92fa5e9a",
   "metadata": {
    "id": "92fa5e9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11901146 0.40487607 0.23440581 0.0250073  0.12402239 0.05488181\n",
      " 0.17591782 0.1785821  0.0512614  0.26891235 0.4937687 ]\n"
     ]
    }
   ],
   "source": [
    "# Importa la función pearsonr\n",
    "from scipy.stats import pearsonr\n",
    "# Importa numpy\n",
    "import numpy as np\n",
    "#Determina la cantidad de variables\n",
    "n = X.shape[1]\n",
    "# Inicializa el vector de correlaciones\n",
    "cor = np.zeros(n)\n",
    "# Realiza la comparación entre Y y cada columna de X\n",
    "for i in range(n):\n",
    "      cor[i] = abs(pearsonr(X.iloc[:, i], Y)[0])\n",
    "# Imprime el resultado\n",
    "print(cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0963052",
   "metadata": {
    "id": "c0963052"
   },
   "source": [
    "Una vez que conocemos la correlación que cada variable de entrada tiene con la variable de salida, podemos clasificarlas de mayor a menor, para entonces empezar a generar modelos. En la siguiente celda, almacenaremos dicho orden en una variable de nombre `ind`. Para lograrlo, nos ayudaremos de la función `argsort` de numpy, y ya que nos interesa que el orden sea de mayor a menor, pero la función genera el orden contrario, le entregaremos a la función como parámetro los valores negativos de correlación.\n",
    "\n",
    "Solamente por curiosidad, también aprovecharemos para revisar el nombre de dichas variables, y así saber cómo se empezará a construir nuestro modelo. Para lograrlo, simplemente imprimiremos en pantalla los nombres de las columnas de X, pero en el orden indicado por el arreglo `ind`, esto con ayuda de la función `columns` de pandas.<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    ind = np.argsort(-cor)<br>\n",
    "    print(df.columns[ind])\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0241d34",
   "metadata": {
    "id": "b0241d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['alcohol', 'acidezVolatil', 'sulfatos', 'acidoCitrico', 'densidad',\n",
      "       'dioxidoAzufreTotal', 'cloruros', 'acidezFija', 'dioxidoAzufreLibre',\n",
      "       'pH', 'azucarResidual'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Almacena el orden de las variables\n",
    "ind = np.argsort(-cor)\n",
    "# Imprime los nombres de las variables en el orden del ranking\n",
    "print(df.columns[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb7035a",
   "metadata": {
    "id": "fcb7035a"
   },
   "source": [
    "Probablemente tus resultados indiquen la variable de mayor interés es el nivel de alcohol (podría haber variaciones dependiendo de la partición original de datos), seguido de la acidez volátil, hasta eventualmente llegar al azucar residual. Ahora sí, podremos empezar a generar modelos y revisar sus desempeños, medidos en término de la R cuadrada ajustada. Primero generaremos un modelo de regresión lineal simple que solamente incluya la mejor variable, después un modelo de regresión lineal múltiple que incluya las mejores dos variables, después uno con las tres mejores variables, y así sucesivamente hasta terminar con un modelo que incluya todas las variables del sistema.\n",
    "\n",
    "Para lograrlo, primero inicializaremos un arreglo de nombre `Radj`, donde se irá almacenando la métrica de desempeño de cada modelo. Después declararemos un bucle `for` que recorrerá todas las variables de X. Dentro de dicho bucle, primero definiremos una X temporal con el nombre `Xtemp`, que incluirá solamente las variables de interés de la iteración correspondiente (desde 0 hasta *i*). Después generaremos y ajustaremos un modelo de regresión lineal múltiple en una sola línea de código (basándonos en las instrucciones que hemos usado previamente). La última tarea dentro del bucle consistirá en calcular y almacenar la R cuadrada ajustada; dicha tarea la resolveremos con la función `rsquared_adj` de la librería statsmodels, la misma de la que deriva la función `OLS` que usaremos para ajustar el modelo. Por lo mismo, primero tendremos que importar dicha librería. Finalmente, y para revisar los resultados, imprimiremos en pantalla el contenido del arreglo `Radj`.<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    import statsmodels.api as sm<br>\n",
    "    Radj=np.zeros(len(ind))<br>\n",
    "    for i in range(len(ind)):<br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Xtemp=X.iloc[:,ind[0:i]]<br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;modelTemp=sm.OLS(Y,sm.add_constant(Xtemp)).fit()<br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Radj[i]=modelTemp.rsquared_adj<br>\n",
    "    print(Radj)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "061d2f41",
   "metadata": {
    "id": "061d2f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.44089210e-16 2.43215362e-01 3.38290905e-01 3.57966677e-01\n",
      " 3.57940253e-01 3.57656743e-01 3.62791709e-01 3.68075531e-01\n",
      " 3.70642535e-01 3.70853320e-01 3.72309329e-01]\n"
     ]
    }
   ],
   "source": [
    "# Importar la librería\n",
    "import statsmodels.api as sm\n",
    "# Inicializar el arreglo Radj\n",
    "Radj=np.zeros(len(ind))\n",
    "# Bucle for en el que se creará Xtemp, se entrenará el modelo, y se evaluará y almacenará Radj\n",
    "for i in range(len(ind)):\n",
    "      Xtemp=X.iloc[:,ind[0:i]]\n",
    "      modelTemp=sm.OLS(Y,sm.add_constant(Xtemp)).fit()\n",
    "      Radj[i]=modelTemp.rsquared_adj\n",
    "# Imprimir resultados\n",
    "print(Radj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16e2f39",
   "metadata": {
    "id": "e16e2f39"
   },
   "source": [
    "Una vez que conocemos dichos resultados, podemos tomar la decisión de qué variables seleccionar para nuestro modelo. Sin embargo, en ocasiones resulta más sencillo tomar esa decisión después de visualizar los resultados en una gráfica.\n",
    "\n",
    "En la siguiente celda, genera una gráfica para la variable `Radj`, definiendo como segundo parámetro el término `o-`, que provocará que cada valor se grafique como un pequeño punto, y que cada punto esté unido por una línea. La gráfica se generará con la función `plot` de la librería matplotlib.pyplot, así que no olvides primero importar dicha librería.<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    import matplotlib.pyplot as plt<br>\n",
    "    plt.plot(Radj,'o-')\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c5c27f3",
   "metadata": {
    "id": "7c5c27f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20e74137ad0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importa la librería\n",
    "import matplotlib.pyplot as plt\n",
    "# Genera la gráfica\n",
    "plt.plot(Radj,'o-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2245cf9",
   "metadata": {
    "id": "a2245cf9"
   },
   "source": [
    "Sin duda hay muchas cosas que podríamos agregar y modificar a la gráfica para que se vea mejor y su significado sea más claro. Pero, ya que de momento solo la estamos creando para nuestros propios ojos, no necesitamos más que la visualización más básica.\n",
    "\n",
    "A partir de dicha gráfica, en mi caso, podría considerar que las primeras 6 variables serían las adecuadas para seleccionar en mi modelo. Dependiendo de la separación inicial de datos, en tu caso, la imagen podría indicar algo distinto. Por simple conveniencia y para estandarizar nuestros resultados, asumamos que tomamos la decisión de seleccionar solamente las 6 variables mejor clasificadas.\n",
    "\n",
    "A partir de este punto podríamos decir que ya realizamos una selección de características y terminar el ejercicio. Sin embargo, revisemo ahora la metodología de eliminación hacia atrás a partir de estos resultados. Es decir, veamos si podemos deshacernos de uno o varias de estas 6 variables, sin perjudicar el desempeño del modelo.\n",
    "\n",
    "Generemos entonces 6 modelos de regresión múltiple, cada uno con 5 variables. Primero definiremos un *data frame* de nombre `Xfs` (X después de realizar *forward selection*) que contenga solamente las variables de interés, e inicializaremos una vez más un arreglo de nombre `RadjBE` (Radj después de realizar *backwards elimination*) donde se almacenará el desempeño de cada modelo.\n",
    "\n",
    "Posteriormente, crearemos un bucle *for* con una estructura similar al utilizado en la etapa de selección hacia adelante. Primero se definirá `Xtemp` como la X temporal que constará de una columna menos que XFS, después se creará y entrenará el modelo, y por último se calculará y almacenará la métrica de desempeño. Una vez terminado este proceso, imprimiremos en consola los resultados de cada uno de estos modelos, así como el desempeño del modelo original (el que incluía las 6 variables, recordando que en Python el primer elemento tiene índice 0).\n",
    "\n",
    "Trataré de dejar un poco más claro el proceso con el que crearemos `Xtemp`. Usaremos la función `drop` de pandas para eliminar la *i* columna, definiendo como parámetros `labels` y `axis`. Para el primero, especificaremos el nombre de la columna *i* usando la función `columns`, y para el segundo, simplemente lo definiremos como `1`.<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    Xfs=X.iloc[:,ind[:6]]<br>\n",
    "    RadjBE=np.zeros(6)<br>\n",
    "    for i in range(len(RadjBE)):<br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Xtemp=Xfs.drop(labels = Xfs.columns[i], axis = 1)<br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;modelTemp=sm.OLS(Y,sm.add_constant(Xtemp)).fit()<br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RadjBE[i]=modelTemp.rsquared_adj<br>\n",
    "    print(RadjBE)<br>\n",
    "    print(Radj[5])\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b0a9a11",
   "metadata": {
    "id": "2b0a9a11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2566666  0.31346739 0.34229937 0.36303159 0.36324735 0.35765674]\n",
      "0.35765674330809183\n"
     ]
    }
   ],
   "source": [
    "# Genera el data frame Xfs con solo la información de las 6 mejores variables\n",
    "Xfs=X.iloc[:,ind[:6]]\n",
    "# Inicializa RadjBE\n",
    "RadjBE=np.zeros(6)\n",
    "# Bucle for en el que se creará Xtemp, se entrenará el modelo, y se evaluará y almacenará RadjBE\n",
    "for i in range(len(RadjBE)):\n",
    "      Xtemp=Xfs.drop(labels = Xfs.columns[i], axis = 1)\n",
    "      modelTemp=sm.OLS(Y,sm.add_constant(Xtemp)).fit()\n",
    "      RadjBE[i]=modelTemp.rsquared_adj\n",
    "# Imprime los resultados\n",
    "print(RadjBE)\n",
    "# Imprime el resultado del modelo con las 6 mejores variables\n",
    "print(Radj[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719bf4da",
   "metadata": {
    "id": "719bf4da"
   },
   "source": [
    "Al revisar los resultados, en mi caso, se aprecia que el modelo que no incluye la quinta variable tiene el mejor desempeño de entre los 6 modelos de cinco variables, y que, además, tiene un mejor desempeño que el modelo con 6 variables. Por lo tanto, podemos eliminar dicha variable de nuestro modelo. Incluso si en tus resultados hay diferencias, una vez más, en aras de estandarizar nuestro trabajo, tomemos la decisión de eliminar la quinta variable.\n",
    "\n",
    "Podríamos, y deberíamos, repetir este proceso, para así tratar de reducir el modelo tanto como sea posible. Sin embargo, de momento dejemos el ejercicio hasta ese punto. Ahora podríamos realizar el mismo proceso que generamos en la lectura interactiva previa y encontrar el RSE y R cuadrada de este modelo en los datos de prueba.\n",
    "\n",
    "Para finalizar, simplemente quiero mostrarles una implementación exageradamente sencilla del método Lasso. Usando la función `Lasso` de la librería sklearn.linear_model, no necesitamos más que definir el valor de lambda (aquí llamado alpha), y entregarle a la función los datos. En la siguiente celda importa la función, crea el modelo con un lambda de 0.1, entrénalo con la función `fit`, e imprime el valor de los coeficientes estimados con la función `coef_`.<br><br>\n",
    "\n",
    "<details>\n",
    "    <summary>Si tienes problemas, da un click aquí para mostrar la solución</summary>\n",
    "    from sklearn.linear_model import Lasso<br>\n",
    "    modelL=Lasso(alpha=0.1)<br>\n",
    "    modelL.fit(X,Y)<br>\n",
    "    print(modelL.coef_)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8619043",
   "metadata": {
    "id": "e8619043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02751269 -0.          0.          0.         -0.          0.00389581\n",
      " -0.00316165 -0.         -0.          0.          0.27463404]\n"
     ]
    }
   ],
   "source": [
    "# Importa la librería\n",
    "from sklearn.linear_model import Lasso\n",
    "# Crea el modelo\n",
    "modelL=Lasso(alpha=0.1)\n",
    "# Entrena el modelo\n",
    "modelL.fit(X,Y)\n",
    "# Imprime el valor de los coeficientes\n",
    "print(modelL.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611571f1",
   "metadata": {
    "id": "611571f1"
   },
   "source": [
    "Como podrás observar, muchos de los coeficientes tienen valor 0, indicando que el método de Lasso realizó una selección de características inherente. Con estas 4 líneas de código podemos llegar a reemplazar todo el trabajo que habíamos generado previamente. Pero, si nos interesa el proceso de selección hacia adelante y eliminación hacia atrás, también podemos apoyarnos en funciones para realizar el proceso de forma extremadamente sencilla y veloz. Por ejemplo, la función `SequentialFeatureSelector` de la librería sklearn.feature_selection puede generar tanto la selección hacia adelante como la eliminación hacia atrás con tan pocas líneas de código como el proceso de Lasso que acabamos de ejecutar.\n",
    "\n",
    "Con esto finalizamos la lectura interactiva, hasta la próxima."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
